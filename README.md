# ProxyHunter ğŸš€

<div align="center">

![ProxyHunter Logo](https://img.shields.io/badge/ProxyHunter-2.3.0-blue.svg)
[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![GitHub Stars](https://img.shields.io/github/stars/sheng1111/Proxy-Hunter.svg)](https://github.com/sheng1111/Proxy-Hunter/stargazers)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/sheng1111/Proxy-Hunter)

**ğŸ”¥ Professional proxy management with SOCKS support, geographic targeting, and AI-powered validation**

[English](#english) | [ç¹é«”ä¸­æ–‡](#ç¹é«”ä¸­æ–‡) | [æ—¥æœ¬èª](#æ—¥æœ¬èª)

</div>

---

## English

ProxyHunter is the ultimate proxy management solution for red team operators, web scrapers, and security professionals who demand enterprise-grade proxy capabilities with cutting-edge features.

### ğŸ”¥ Revolutionary Features

- ğŸš€ **15+ Premium Proxy Sources** - GitHub, ProxyScrape, SOCKS proxy lists, and specialized sources
- ğŸ›¡ï¸ **SOCKS4/SOCKS5 Support** - Complete SOCKS proxy detection, validation, and management
- ğŸŒ **Geographic Intelligence** - Real-time IP geolocation with country/city/ISP detection
- ğŸ¯ **AI-Powered Quality Scoring** - Dynamic proxy ranking based on performance metrics
- âš¡ **Enhanced Validation Engine** - Socket + HTTP dual-layer testing with 7 endpoints
- ğŸ”’ **Advanced Anonymity Detection** - Elite, Anonymous, Transparent with header leak analysis
- ğŸš« **Smart Blacklist System** - Automatic failed proxy filtering and performance tracking
- ğŸ’¾ **Enhanced Database Analytics** - SQLite with geographic distribution and quality metrics
- ğŸŒ **Modern Web Dashboard** - Real-time monitoring with advanced filtering and search
- ğŸ“Š **Interactive Analytics** - Protocol distribution, geographic insights, performance graphs
- ğŸ› ï¸ **Comprehensive RESTful API** - Full programmatic control with enhanced endpoints
- ğŸ **Professional Python Library** - One-line access with intelligent caching and rotation
- ğŸ”„ **Intelligent Pool Management** - Auto-refresh, quality-based selection, and warming
- âš¡ **Lightning-Fast Performance** - 50 concurrent threads, sub-second proxy access

### ğŸ¯ Red Team & Penetration Testing

- **ğŸŒ Geographic Operations** - Target-specific country/region proxy filtering
- **ğŸ”’ Elite SOCKS Proxies** - High-anonymity SOCKS4/SOCKS5 for advanced operations
- **âš¡ Speed Optimization** - Sub-1-second response time filtering with quality scoring
- **ğŸ›¡ï¸ Stealth Validation** - Socket-level testing before HTTP to avoid detection
- **ğŸ”„ Advanced Rotation** - Performance-based proxy selection with auto-failover
- **ğŸ“¡ Tool Integration** - Native export for Burp Suite, Metasploit, curl, Python
- **ğŸš« Anti-Blacklist** - Automatic failed proxy removal and fresh pool management
- **ğŸ“Š Operation Analytics** - Success rates, geographic distribution, performance metrics

### ğŸ•·ï¸ Web Scraping & Enterprise Automation

- **ğŸš€ High-Volume Processing** - 50 concurrent threads, 1000+ proxies per minute
- **ğŸŒ Global Proxy Network** - Access proxies from 50+ countries worldwide
- **ğŸ“ˆ Performance Intelligence** - Real-time quality scoring and response analytics
- **ğŸ’¾ Enterprise Database** - SQLite with advanced indexing and query optimization
- **ğŸ”„ Smart Rotation** - AI-powered proxy selection based on success patterns
- **ğŸ“Š Real-Time Dashboard** - Live monitoring with WebSocket updates and filtering
- **ğŸ› ï¸ API Integration** - RESTful API for enterprise automation and integration

### ğŸš€ Quick Start

#### Installation

```bash
# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows

# Install from PyPI
pip install proxy-meshx

# Or install from source for latest features
git clone https://github.com/sheng1111/Proxy-Hunter.git
cd Proxy-Hunter
pip install -e .
```

**Note:** Package name is `proxy-meshx`, import as `proxyhunter`:

```python
from proxyhunter import ProxyHunter, get_proxy
```

#### Command Line Usage

```bash
# Quick proxy scan with enhanced validation
proxyhunter scan --threads 30 --limit 100 --anonymous-only

# Launch modern web dashboard
proxyhunter web --port 8080

# Or using Python module
python -m proxyhunter.web_app
```

#### One-Line Proxy Access ğŸ”¥

```python
from proxyhunter import get_proxy, get_proxies, get_socks_proxies, get_elite_proxies
import requests

# Get any working proxy instantly
proxy_url = get_proxy()
response = requests.get('https://httpbin.org/ip',
                       proxies={'http': proxy_url, 'https': proxy_url})
print(f"Your IP: {response.json()['origin']}")

# Get high-quality US proxies with minimum quality score
us_proxies = get_proxies(count=5, country='US', min_quality=70, max_response_time=2.0)
print(f"Found {len(us_proxies)} high-quality US proxies")

# Get SOCKS proxies for advanced operations
socks_proxies = get_socks_proxies(count=3, protocol='socks5')
print(f"SOCKS5 proxies: {socks_proxies}")

# Get elite anonymity proxies for red team operations
elite_proxies = get_elite_proxies(count=5)
print(f"Elite proxies: {elite_proxies}")

# Geographic filtering with quality constraints
uk_proxies = get_proxies(count=3, country='UK', min_quality=60, anonymous_only=True)
```

#### Advanced Usage with Enhanced Features

```python
from proxyhunter import ProxyHunter, ProxySession

# Professional ProxyHunter with SOCKS and geolocation support
hunter = ProxyHunter(
    threads=50,                    # Maximum concurrent validation
    enable_socks=True,             # Include SOCKS4/SOCKS5 proxies
    enable_geolocation=True,       # Geographic IP detection
    auto_blacklist=True,           # Automatic failed proxy filtering
    quality_threshold=50.0,        # Minimum quality score
    anonymous_only=False,          # Allow all proxy types
    validate_on_fetch=True         # Immediate validation
)

# Fetch from all sources including SOCKS
proxies = hunter.fetch_proxies()
print(f"Fetched {len(proxies)} unique proxies from 15+ sources")

# Enhanced filtering and analytics
socks_proxies = hunter.get_socks_proxies(limit=10)
quality_proxies = hunter.get_proxies_by_quality(min_quality_score=80, limit=5)
us_proxies = hunter.get_proxies_by_geolocation(country_code='US', limit=10)
elite_proxies = hunter.get_elite_proxies_enhanced(limit=5)

# Comprehensive analytics
analytics = hunter.get_proxy_analytics()
print(f"Protocol distribution: {analytics['protocol_distribution']}")
print(f"Geographic distribution: {analytics['geographic_distribution']}")
print(f"Quality distribution: {analytics['quality_distribution']}")

# Search proxies by criteria
london_proxies = hunter.search_proxies("London", limit=5)
aws_proxies = hunter.search_proxies("Amazon", limit=3)

# ProxySession with enhanced rotation
session = ProxySession(
    proxy_count=20,
    rotation_strategy='quality_based',  # Use highest quality proxies
    country_filter='US',
    protocol_filter='http',
    min_quality=60
)

response = session.get('https://httpbin.org/ip')
print(f"Response via quality proxy: {response.json()}")
```

### ğŸ”¥ Enhanced Quick Scan with SOCKS Support

```python
from proxyhunter import quick_scan, get_proxy_stats, search_proxies

# Professional scan with SOCKS and geolocation
working_proxies = quick_scan(
    threads=50,           # Maximum performance
    include_socks=True,   # Include SOCKS4/SOCKS5
    limit=200,
    anonymous_only=False
)
print(f"Found {len(working_proxies)} working proxies")

# Scan specific sources including SOCKS
socks_sources = ['github-socks5', 'proxyscrape-socks', 'socks-proxy-list']
socks_proxies = quick_scan(
    sources=socks_sources,
    include_socks=True,
    threads=30
)

# Get elite anonymous proxies with enhanced filtering
elite_proxies = quick_scan(
    anonymous_only=True,
    include_socks=True,
    threads=40,
    limit=100
)

# Comprehensive proxy analytics
stats = get_proxy_stats()
print(f"Protocol distribution: {stats['protocol_distribution']}")
print(f"Total working proxies: {stats['performance_metrics']['total_working']}")

# Search for specific geographic proxies
us_proxies = search_proxies("United States", limit=10)
tokyo_proxies = search_proxies("Tokyo", limit=5)
```

### ğŸ¯ Red Team Use Cases with Enhanced Capabilities

#### Advanced Multi-Protocol Reconnaissance

```python
from proxyhunter import get_proxies, get_socks_proxies, get_elite_proxies
import requests
import random

# Multi-protocol reconnaissance with geographic distribution
countries = ['US', 'UK', 'DE', 'JP', 'CA', 'AU', 'NL', 'FR']
reconnaissance_proxies = {}

for country in countries:
    # Get high-quality HTTP/HTTPS proxies
    http_proxies = get_proxies(count=2, country=country, min_quality=60, max_response_time=3.0)
    # Get SOCKS proxies for advanced operations
    socks_proxies = get_socks_proxies(count=1, protocol='socks5')

    reconnaissance_proxies[country] = {
        'http': http_proxies,
        'socks': socks_proxies
    }
    print(f"ğŸ“ {country}: {len(http_proxies)} HTTP + {len(socks_proxies)} SOCKS proxies")

# Elite proxy pool for sensitive operations
elite_ops_proxies = get_elite_proxies(count=10)
print(f"ğŸ”’ Elite proxy pool: {len(elite_ops_proxies)} proxies")

# Target enumeration with proxy rotation and anonymity levels
targets = ["example.com", "test.com", "demo.org"]
user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36'
]

for target in targets:
    for country, proxy_sets in reconnaissance_proxies.items():
        for proxy_url in proxy_sets['http'][:1]:  # Use first proxy from each country
            try:
                headers = {
                    'User-Agent': random.choice(user_agents),
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
                }
                response = requests.get(
                    f"https://{target}",
                    proxies={'http': proxy_url, 'https': proxy_url},
                    headers=headers,
                    timeout=10,
                    verify=False
                )
                print(f"âœ… {country} -> {target}: {response.status_code} ({len(response.content)} bytes)")
            except Exception as e:
                print(f"âŒ {country} -> {target}: {str(e)[:50]}")
```

#### SOCKS Tunnel Operations

```python
from proxyhunter import get_socks_proxies, search_proxies

# Establish SOCKS tunnels for advanced operations
socks5_proxies = get_socks_proxies(count=5, protocol='socks5')
socks4_proxies = get_socks_proxies(count=3, protocol='socks4')

print("ğŸ”§ SOCKS5 Tunnels:")
for proxy in socks5_proxies:
    print(f"   socks5://{proxy.split('://')[-1]}")

print("ğŸ”§ SOCKS4 Tunnels:")
for proxy in socks4_proxies:
    print(f"   socks4://{proxy.split('://')[-1]}")

# Search for specific ISP or cloud provider proxies
aws_proxies = search_proxies("Amazon", limit=5)
azure_proxies = search_proxies("Microsoft", limit=3)
print(f"â˜ï¸ Cloud proxies: {len(aws_proxies)} AWS + {len(azure_proxies)} Azure")
```

#### OSINT with Enhanced Geographic Intelligence

```python
from proxyhunter import ProxySession, get_proxy_stats

# Create region-specific sessions with quality thresholds
sessions = {
    'North_America': ProxySession(
        proxy_count=8,
        country_filter='US',
        min_quality=70,
        anonymous_only=True
    ),
    'Europe': ProxySession(
        proxy_count=6,
        country_filter='UK',
        min_quality=65,
        protocol_filter='http'
    ),
    'Asia_Pacific': ProxySession(
        proxy_count=5,
        country_filter='JP',
        min_quality=60,
        rotation_strategy='quality_based'
    )
}

# Perform enhanced OSINT from different geographic locations
targets = ["linkedin.com", "twitter.com", "facebook.com", "github.com"]
for region, session in sessions.items():
    print(f"\nğŸŒ Starting OSINT from {region}")
    for target in targets:
        try:
            response = session.get(f"https://{target}", timeout=15)
            print(f"âœ… [{region}] {target}: {response.status_code} ({response.headers.get('server', 'Unknown')})")
        except Exception as e:
            print(f"âŒ [{region}] {target}: {str(e)[:50]}")

# Display comprehensive analytics
analytics = get_proxy_stats()
print(f"\nğŸ“Š Global Proxy Analytics:")
print(f"   Active Proxies: {analytics['performance_metrics']['total_working']}")
print(f"   Geographic Distribution: {analytics['geographic_distribution']}")
```

### ğŸŒ Enhanced Web Dashboard

Launch the professional web interface:

```bash
python -m proxyhunter.web_app
# Visit http://localhost:5000
```

**New Dashboard Features:**

- ğŸ“Š **Real-Time Analytics** - Live proxy statistics with WebSocket updates
- ğŸ“ˆ **Performance Charts** - Response time trends and success rate analysis
- ğŸŒ **Geographic Distribution** - World map showing proxy locations
- ğŸ”„ **One-Click Operations** - Instant proxy refresh and validation
- ğŸ“‹ **Smart Copy** - Copy proxies in various formats (curl, requests, etc.)
- ğŸŒ **Multi-Language UI** - Full interface in 3 languages
- ğŸ“± **Mobile Responsive** - Works perfectly on all devices
- ğŸ¨ **Modern Design** - Clean, professional interface

### ğŸš¦ Traffic Monitoring Dashboard

Access advanced monitoring at `/traffic`:

```bash
# Start dashboard and visit http://localhost:5000/traffic
python -m proxyhunter.web_app
```

**Traffic Monitor Features:**

- ğŸ“ˆ **Real-Time Request Tracking** - Live monitoring of all proxy requests
- ğŸ“Š **Success/Failure Analytics** - Visual success rate analysis
- ğŸŒ **Geographic Usage Stats** - Proxy usage by country and region
- â±ï¸ **Response Time Analysis** - Detailed latency statistics
- ğŸ“Š **Data Transfer Monitoring** - Track bandwidth usage per proxy
- ğŸ”„ **Active Session Management** - Monitor all active proxy sessions
- ğŸ“ **Detailed Request Logs** - Complete request/response logging
- ğŸš¦ **Live Updates** - WebSocket-powered real-time updates

---

## ç¹é«”ä¸­æ–‡

ProxyHunter æ˜¯çµ‚æ¥µä»£ç†ç®¡ç†è§£æ±ºæ–¹æ¡ˆï¼Œå°ˆç‚ºç´…éšŠæ“ä½œå“¡ã€ç¶²é çˆ¬èŸ²é–‹ç™¼è€…å’Œè³‡å®‰å°ˆæ¥­äººå“¡æ‰“é€ ï¼Œæä¾›ä¼æ¥­ç´šä»£ç†åŠŸèƒ½å’Œå°–ç«¯ç‰¹è‰²ã€‚

### ğŸ”¥ é©æ–°åŠŸèƒ½

- ğŸš€ **15+å€‹é ‚ç´šä»£ç†æº** - GitHubã€ProxyScrapeã€SOCKS ä»£ç†æ¸…å–®å’Œå°ˆæ¥­ä¾†æº
- ğŸ›¡ï¸ **SOCKS4/SOCKS5 æ”¯æ´** - å®Œæ•´çš„ SOCKS ä»£ç†æª¢æ¸¬ã€é©—è­‰å’Œç®¡ç†
- ğŸŒ **åœ°ç†æ™ºèƒ½** - å³æ™‚ IP åœ°ç†å®šä½ï¼Œæ”¯æ´åœ‹å®¶/åŸå¸‚/ISP æª¢æ¸¬
- ğŸ¯ **AI é©…å‹•å“è³ªè©•åˆ†** - åŸºæ–¼æ•ˆèƒ½æŒ‡æ¨™çš„å‹•æ…‹ä»£ç†æ’å
- âš¡ **å¢å¼·é©—è­‰å¼•æ“** - Socket + HTTP é›™å±¤æ¸¬è©¦ï¼Œæ”¯æ´ 7 å€‹ç«¯é»
- ğŸ”’ **é€²éšåŒ¿åæ€§æª¢æ¸¬** - Eliteã€Anonymousã€Transparent èˆ‡æ¨™é ­æ´©æ¼åˆ†æ
- ğŸš« **æ™ºèƒ½é»‘åå–®ç³»çµ±** - è‡ªå‹•å¤±æ•ˆä»£ç†éæ¿¾å’Œæ•ˆèƒ½è¿½è¹¤
- ğŸ’¾ **å¢å¼·è³‡æ–™åº«åˆ†æ** - SQLite æ­é…åœ°ç†åˆ†ä½ˆå’Œå“è³ªæŒ‡æ¨™
- ğŸŒ **ç¾ä»£åŒ– Web å„€è¡¨æ¿** - å³æ™‚ç›£æ§èˆ‡é€²éšéæ¿¾å’Œæœå°‹
- ğŸ“Š **äº’å‹•å¼åˆ†æ** - å”å®šåˆ†ä½ˆã€åœ°ç†æ´å¯Ÿã€æ•ˆèƒ½åœ–è¡¨
- ğŸ› ï¸ **å®Œæ•´ RESTful API** - å…¨é¢ç¨‹å¼åŒ–æ§åˆ¶èˆ‡å¢å¼·ç«¯é»
- ğŸ **å°ˆæ¥­ Python å‡½å¼åº«** - ä¸€è¡Œå­˜å–ï¼Œæ™ºèƒ½å¿«å–å’Œè¼ªæ›
- ğŸ”„ **æ™ºèƒ½æ± ç®¡ç†** - è‡ªå‹•åˆ·æ–°ã€åŸºæ–¼å“è³ªé¸æ“‡å’Œé ç†±
- âš¡ **é–ƒé›»èˆ¬æ•ˆèƒ½** - 50 å€‹ä½µç™¼åŸ·è¡Œç·’ï¼Œäºç§’ç´šä»£ç†å­˜å–

### ğŸ¯ ç´…éšŠ & æ»²é€æ¸¬è©¦

- **ğŸŒ åœ°ç†æ“ä½œ** - ç›®æ¨™ç‰¹å®šåœ‹å®¶/åœ°å€ä»£ç†éæ¿¾
- **ğŸ”’ Elite SOCKS ä»£ç†** - é€²éšæ“ä½œçš„é«˜åŒ¿å SOCKS4/SOCKS5
- **âš¡ é€Ÿåº¦æœ€ä½³åŒ–** - äºç§’ç´šå›æ‡‰æ™‚é–“éæ¿¾èˆ‡å“è³ªè©•åˆ†
- **ğŸ›¡ï¸ éš±è”½é©—è­‰** - HTTP å‰ Socket å±¤ç´šæ¸¬è©¦é¿å…åµæ¸¬
- **ğŸ”„ é€²éšè¼ªæ›** - åŸºæ–¼æ•ˆèƒ½çš„ä»£ç†é¸æ“‡èˆ‡è‡ªå‹•æ•…éšœè½‰ç§»
- **ğŸ“¡ å·¥å…·æ•´åˆ** - åŸç”ŸåŒ¯å‡ºè‡³ Burp Suiteã€Metasploitã€curlã€Python
- **ğŸš« åé»‘åå–®** - è‡ªå‹•ç§»é™¤å¤±æ•ˆä»£ç†å’Œæ–°æ± ç®¡ç†
- **ğŸ“Š æ“ä½œåˆ†æ** - æˆåŠŸç‡ã€åœ°ç†åˆ†ä½ˆã€æ•ˆèƒ½æŒ‡æ¨™

### ğŸ•·ï¸ ç¶²é çˆ¬èŸ² & ä¼æ¥­è‡ªå‹•åŒ–

- **ğŸš€ å¤§é‡è™•ç†** - 50 å€‹ä½µç™¼åŸ·è¡Œç·’ï¼Œæ¯åˆ†é˜ 1000+å€‹ä»£ç†
- **ğŸŒ å…¨çƒä»£ç†ç¶²è·¯** - å­˜å–ä¾†è‡ª 50+å€‹åœ‹å®¶çš„ä»£ç†
- **ğŸ“ˆ æ•ˆèƒ½æ™ºèƒ½** - å³æ™‚å“è³ªè©•åˆ†å’Œå›æ‡‰åˆ†æ
- **ğŸ’¾ ä¼æ¥­è³‡æ–™åº«** - SQLite æ­é…é€²éšç´¢å¼•å’ŒæŸ¥è©¢æœ€ä½³åŒ–
- **ğŸ”„ æ™ºèƒ½è¼ªæ›** - AI é©…å‹•çš„ä»£ç†é¸æ“‡åŸºæ–¼æˆåŠŸæ¨¡å¼
- **ğŸ“Š å³æ™‚å„€è¡¨æ¿** - WebSocket æ›´æ–°å’Œéæ¿¾çš„å³æ™‚ç›£æ§
- **ğŸ› ï¸ API æ•´åˆ** - ä¼æ¥­è‡ªå‹•åŒ–å’Œæ•´åˆçš„ RESTful API

### ğŸš€ å¿«é€Ÿé–‹å§‹

#### å®‰è£

```bash
# å»ºç«‹è™›æ“¬ç’°å¢ƒï¼ˆå»ºè­°ï¼‰
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å¾ PyPI å®‰è£
pip install proxy-meshx

# æˆ–å¾åŸå§‹ç¢¼å®‰è£ä»¥ç²å¾—æœ€æ–°åŠŸèƒ½
git clone https://github.com/sheng1111/Proxy-Hunter.git
cd Proxy-Hunter
pip install -e .
```

**æ³¨æ„ï¼š** å¥—ä»¶åç¨±ç‚º `proxy-meshx`ï¼ŒåŒ¯å…¥æ™‚ä½¿ç”¨ `proxyhunter`ï¼š

```python
from proxyhunter import ProxyHunter, get_proxy
```

#### æŒ‡ä»¤åˆ—ä½¿ç”¨

```bash
# å¿«é€Ÿä»£ç†æƒæï¼Œå¢å¼·é©—è­‰
proxyhunter scan --threads 30 --limit 100 --anonymous-only

# å•Ÿå‹•ç¾ä»£åŒ– Web å„€è¡¨æ¿
proxyhunter web --port 8080

# æˆ–ä½¿ç”¨ Python æ¨¡çµ„
python -m proxyhunter.web_app
```

#### ä¸€è¡Œä»£ç¢¼å–å¾—ä»£ç† ğŸ”¥

```python
from proxyhunter import get_proxy, get_proxies, get_socks_proxies, get_elite_proxies
import requests

# ç«‹å³å–å¾—ä»»ä½•å¯ç”¨ä»£ç†
proxy_url = get_proxy()
response = requests.get('https://httpbin.org/ip',
                       proxies={'http': proxy_url, 'https': proxy_url})
print(f"æ‚¨çš„ IPï¼š{response.json()['origin']}")

# å–å¾—é«˜å“è³ªç¾åœ‹ä»£ç†ï¼Œæœ€ä½å“è³ªè©•åˆ†è¦æ±‚
us_proxies = get_proxies(count=5, country='US', min_quality=70, max_response_time=2.0)
print(f"æ‰¾åˆ° {len(us_proxies)} å€‹é«˜å“è³ªç¾åœ‹ä»£ç†")

# å–å¾—é€²éšæ“ä½œç”¨çš„ SOCKS ä»£ç†
socks_proxies = get_socks_proxies(count=3, protocol='socks5')
print(f"SOCKS5 ä»£ç†ï¼š{socks_proxies}")

# å–å¾—ç´…éšŠæ“ä½œç”¨çš„ Elite åŒ¿åä»£ç†
elite_proxies = get_elite_proxies(count=5)
print(f"Elite ä»£ç†ï¼š{elite_proxies}")

# åœ°ç†éæ¿¾æ­é…å“è³ªé™åˆ¶
uk_proxies = get_proxies(count=3, country='UK', min_quality=60, anonymous_only=True)
```

#### é€²éšä½¿ç”¨

```python
from proxyhunter import ProxyHunter, ProxySession

# å…·å‚™ 15+å€‹æºçš„å¢å¼·ç‰ˆ ProxyHunter
hunter = ProxyHunter(
    threads=30,              # é«˜é€Ÿé©—è­‰
    anonymous_only=True,     # åƒ… Elite ä»£ç†
    timeout=8,              # åˆç†è¶…æ™‚
    validate_on_fetch=True   # ç«‹å³é©—è­‰
)

# å¾æ‰€æœ‰ 15+å€‹æºç²å–ä»£ç†
proxies = hunter.fetch_proxies()
print(f"{len(proxies)}å€‹çš„å”¯ä¸€ä»£ç†")

# å–å¾—ç²å–çµ±è¨ˆ
stats = hunter.get_fetch_statistics()
print(f"æˆåŠŸç‡ï¼š{stats['sources_successful']}/{stats['sources_attempted']}")

# é€²éšç¯©é¸
us_elite_proxies = hunter.get_proxies_by_country('US', limit=10)
fast_proxies = hunter.get_fast_proxies(max_response_time=2.0, limit=20)

# å…·æœ‰è‡ªå‹•è¼ªæ›çš„ ProxySession
session = ProxySession(
    proxy_count=15,
    rotation_strategy='performance',
    country_filter='US'
)

response = session.get('https://httpbin.org/ip')
print(f"å›æ‡‰ï¼š{response.json()}")

# ç›£æ§æœƒè©±æ•ˆèƒ½
stats = session.get_traffic_stats()
print(f"æˆåŠŸç‡: {stats['successful_requests']}/{stats['total_requests']}")
```

### ğŸ”¥ å¢å¼·å¿«é€Ÿæƒæ

```python
from proxyhunter import quick_scan

# æƒææ‰€æœ‰ 15+å€‹æºï¼Œé«˜é€Ÿé©—è­‰
working_proxies = quick_scan(threads=30, limit=100)
print(f"{len(working_proxies)}å€‹çš„å‹•ä½œä»£ç†")

# åƒ…æƒæç‰¹å®šæº
github_proxies = quick_scan(
    sources=['github-proxy-list', 'github-free-proxies', 'github-proxy-daily'],
    threads=20
)

# åƒ…å–å¾— Elite åŒ¿åä»£ç†
elite_proxies = quick_scan(anonymous_only=True, threads=25, limit=50)
```

### ğŸ¯ ç´…éšŠå¯¦æˆ°æ¡ˆä¾‹

#### åˆ†æ•£åµå¯Ÿ

```python
from proxyhunter import get_proxies
import requests

# åˆ†æ•£åµå¯Ÿçš„ç•°åœ‹ä»£ç†
countries = ['US', 'UK', 'DE', 'CA', 'AU']
all_proxies = []

for country in countries:
    proxies = get_proxies(count=3, country=country, max_response_time=3.0)
    all_proxies.extend(proxies)
    print(f"{country}å¾{len(proxies)}å€‹ä»£ç†")

# åˆ†æ•£ç›®æ¨™åˆ—èˆ‰ä½¿ç”¨
target = "example.com"
for i, proxy in enumerate(all_proxies):
    try:
        response = requests.get(f"http://{target}",
                              proxies={'http': proxy, 'https': proxy},
                              timeout=10, headers={'User-Agent': 'Mozilla/5.0...'})
        print(f"ä»£ç† {i+1}: {response.status_code}")
    except:
        continue
```

#### åœ°ç†åˆ†æ•£ OSINT

```python
from proxyhunter import ProxySession
import requests

# ç‚ºä¸åŒåœ°å€å»ºç«‹å¤šå€‹æœƒè©±
sessions = {}
for region in ['US', 'EU', 'AS']:
    sessions[region] = ProxySession(
        proxy_count=5,
        country_filter=region,
        anonymous_only=True
    )

# ç•°åœ°ç†ä½ç½®åŸ·è¡ŒOSINT
targets = ["linkedin.com", "twitter.com", "facebook.com"]
for region, session in sessions.items():
    for target in targets:
        try:
            response = session.get(f"https://{target}")
            print(f"[{region}] {target}: {response.status_code}")
        except:
            print(f"[{region}] {target}: å¤±æ•—")
```

### ğŸŒ å¼·åŒ– Web å„€è¡¨æ¿

å°ˆæ¥­ Web ä»‹é¢å•Ÿå‹•ï¼š

```bash
python -m proxyhunter.web_app
# http://localhost:5000 è¨ªå•
```

**æ–°å„€è¡¨æ¿åŠŸèƒ½ï¼š**

- ğŸ“Š **å³æ™‚åˆ†æ** - WebSocket å³æ™‚ä»£ç†çµ±è¨ˆ
- ğŸ“ˆ **æ•ˆèƒ½åœ–è¡¨** - å›æ‡‰æ™‚é–“è¶¨å‹¢å’ŒæˆåŠŸç‡åˆ†æ
- ğŸŒ **åœ°ç†åˆ†å¸ƒ** - é¡¯ç¤ºä»£ç†ä½ç½®çš„ä¸–ç•Œåœ°åœ–
- ğŸ”„ **ä¸€éµæ“ä½œ** - å³æ™‚ä»£ç†åˆ·æ–°å’Œé©—è­‰
- ğŸ“‹ **æ™ºèƒ½è¤‡è£½** - å„ç¨®æ ¼å¼ä»£ç†è¤‡è£½ï¼ˆcurlã€requests ç­‰ï¼‰
- ğŸŒ **å¤šèªè¨€ UI** - 3 èªè¨€å®Œæ•´çš„ä»‹é¢
- ğŸ“± **è¡Œå‹•éŸ¿æ‡‰å¼** - æ‰€æœ‰è£ç½®å®Œç¾é‹ä½œ
- ğŸ¨ **ç¾ä»£è¨­è¨ˆ** - ç°¡æ½”ã€å°ˆæ¥­ä»‹é¢

### ğŸš¦ æµé‡ç›£æ§å„€è¡¨æ¿

`/traffic` é«˜åº¦ç›£æ§å­˜å–ï¼š

```bash
# å•Ÿå‹•å„€è¡¨æ¿ä¸¦è¨ªå• http://localhost:5000/traffic
python -m proxyhunter.web_app
```

**æµé‡ç›£æ§åŠŸèƒ½ï¼š**

- ï¿½ï¿½ **å³æ™‚è«‹æ±‚è¿½è¹¤** - æ‰€æœ‰ä»£ç†è«‹æ±‚çš„å³æ™‚ç›£æ§
- ğŸ“Š **æˆåŠŸ/å¤±æ•—åˆ†æ** - è¦–è¦ºçš„æˆåŠŸçš„åˆ†æ
- ğŸŒ **åœ°ç†çš„ä½¿ç”¨çµ±è¨ˆ** - åœ‹å®¶/åœ°å€ä»£ç†ä½¿ç”¨æƒ…æ³
- â±ï¸ **å›æ‡‰æ™‚é–“åˆ†æ** - è©³ç´°çš„å»¶é²çµ±è¨ˆ
- ğŸ“Š **è³‡æ–™å‚³è¼¸ç›£æ§** - æ¯å€‹ä»£ç†çš„å¸¶å¯¬ä½¿ç”¨é‡è¿½è¹¤
- ğŸ”„ **æ´»èºæœƒè©±ç®¡ç†** - ç›£æ§æ‰€æœ‰æ´»èºä»£ç†æœƒè©±
- ğŸ“ **è©³ç´°è«‹æ±‚è¨˜éŒ„** - å®Œæ•´çš„è«‹æ±‚/å›æ‡‰è¨˜éŒ„
- ğŸš¦ **å³æ™‚æ›´æ–°** - WebSocket é©…å‹•çš„å³æ™‚æ›´æ–°

---

## æ—¥æœ¬èª

ProxyHunter ã¯ã€ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ æ“ä½œã€ã‚¦ã‚§ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å°‚é–€å®¶å‘ã‘ã®ç©¶æ¥µã®ãƒ—ãƒ­ã‚­ã‚·ç®¡ç†ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€æœ€å…ˆç«¯æ©Ÿèƒ½ã‚’å‚™ãˆãŸã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚°ãƒ¬ãƒ¼ãƒ‰ã®ãƒ—ãƒ­ã‚­ã‚·æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚

### ğŸ”¥ é©æ–°çš„æ©Ÿèƒ½

- ğŸš€ **15+ã®ãƒ—ãƒ¬ãƒŸã‚¢ãƒ ãƒ—ãƒ­ã‚­ã‚·ã‚½ãƒ¼ã‚¹** - GitHubã€ProxyScrapeã€SOCKS ãƒ—ãƒ­ã‚­ã‚·ãƒªã‚¹ãƒˆã€å°‚é–€ã‚½ãƒ¼ã‚¹
- ğŸ›¡ï¸ **SOCKS4/SOCKS5 å¯¾å¿œ** - å®Œå…¨ãª SOCKS ãƒ—ãƒ­ã‚­ã‚·æ¤œå‡ºã€æ¤œè¨¼ã€ç®¡ç†
- ğŸŒ **åœ°ç†çš„ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹** - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  IP ã‚¸ã‚ªãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå›½/éƒ½å¸‚/ISP æ¤œå‡ºï¼‰
- ğŸ¯ **AI é§†å‹•å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°** - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã«åŸºã¥ãå‹•çš„ãƒ—ãƒ­ã‚­ã‚·ãƒ©ãƒ³ã‚­ãƒ³ã‚°
- âš¡ **å¼·åŒ–æ¤œè¨¼ã‚¨ãƒ³ã‚¸ãƒ³** - Socket + HTTP ãƒ‡ãƒ¥ã‚¢ãƒ«ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ†ã‚¹ãƒˆï¼ˆ7 ã¤ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰
- ğŸ”’ **é«˜åº¦åŒ¿åæ€§æ¤œå‡º** - Eliteã€Anonymousã€Transparent ã§ãƒ˜ãƒƒãƒ€ãƒ¼ãƒªãƒ¼ã‚¯åˆ†æ
- ğŸš« **ã‚¹ãƒãƒ¼ãƒˆãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ ** - è‡ªå‹•å¤±æ•—ãƒ—ãƒ­ã‚­ã‚·ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
- ğŸ’¾ **å¼·åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æ** - åœ°ç†çš„åˆ†å¸ƒã¨å“è³ªæŒ‡æ¨™ã‚’å«ã‚€ SQLite
- ğŸŒ **ãƒ¢ãƒ€ãƒ³ Web ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰** - é«˜åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¨æ¤œç´¢ã«ã‚ˆã‚‹ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
- ğŸ“Š **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–åˆ†æ** - ãƒ—ãƒ­ãƒˆã‚³ãƒ«åˆ†å¸ƒã€åœ°ç†çš„æ´å¯Ÿã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚°ãƒ©ãƒ•
- ğŸ› ï¸ **åŒ…æ‹¬çš„ RESTful API** - å¼·åŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã«ã‚ˆã‚‹å®Œå…¨ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆ¶å¾¡
- ğŸ **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ« Python ãƒ©ã‚¤ãƒ–ãƒ©ãƒª** - ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ 1 è¡Œã‚¢ã‚¯ã‚»ã‚¹
- ğŸ”„ **ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãƒ—ãƒ¼ãƒ«ç®¡ç†** - è‡ªå‹•æ›´æ–°ã€å“è³ªãƒ™ãƒ¼ã‚¹é¸æŠã€ã‚¦ã‚©ãƒ¼ãƒŸãƒ³ã‚°
- âš¡ **è¶…é«˜é€Ÿãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** - 50 åŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰ã€ã‚µãƒ–ç§’ãƒ—ãƒ­ã‚­ã‚·ã‚¢ã‚¯ã‚»ã‚¹

### ğŸ¯ ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ  & ãƒšãƒãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ

- **ğŸŒ åœ°ç†çš„æ“ä½œ** - ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå›ºæœ‰ã®å›½/åœ°åŸŸãƒ—ãƒ­ã‚­ã‚·ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- **ğŸ”’ Elite SOCKS ãƒ—ãƒ­ã‚­ã‚·** - é«˜åº¦æ“ä½œç”¨ã®é«˜åŒ¿å SOCKS4/SOCKS5
- **âš¡ é€Ÿåº¦æœ€é©åŒ–** - å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚µãƒ– 1 ç§’å¿œç­”æ™‚é–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- **ğŸ›¡ï¸ ã‚¹ãƒ†ãƒ«ã‚¹æ¤œè¨¼** - æ¤œå‡ºå›é¿ã®ãŸã‚ã® HTTP å‰ Socket ãƒ¬ãƒ™ãƒ«ãƒ†ã‚¹ãƒˆ
- **ğŸ”„ é«˜åº¦ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³** - è‡ªå‹•ãƒ•ã‚§ã‚¤ãƒ«ã‚ªãƒ¼ãƒãƒ¼ã«ã‚ˆã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·é¸æŠ
- **ğŸ“¡ ãƒ„ãƒ¼ãƒ«çµ±åˆ** - Burp Suiteã€Metasploitã€curlã€Python ã¸ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
- **ğŸš« ã‚¢ãƒ³ãƒãƒ–ãƒ©ãƒƒã‚¯ãƒªã‚¹ãƒˆ** - è‡ªå‹•å¤±æ•—ãƒ—ãƒ­ã‚­ã‚·å‰Šé™¤ã¨æ–°ãƒ—ãƒ¼ãƒ«ç®¡ç†
- **ğŸ“Š æ“ä½œåˆ†æ** - æˆåŠŸç‡ã€åœ°ç†çš„åˆ†å¸ƒã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™

### ğŸ•·ï¸ ã‚¦ã‚§ãƒ–ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° & ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºè‡ªå‹•åŒ–

- **ğŸš€ å¤§é‡å‡¦ç†** - 50 åŒæœŸã‚¹ãƒ¬ãƒƒãƒ‰ã€æ¯åˆ† 1000+ãƒ—ãƒ­ã‚­ã‚·
- **ğŸŒ ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ­ã‚­ã‚·ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯** - ä¸–ç•Œ 50+ã‚«å›½ã‹ã‚‰ã®ãƒ—ãƒ­ã‚­ã‚·ã‚¢ã‚¯ã‚»ã‚¹
- **ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ã‚¹** - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨å¿œç­”åˆ†æ
- **ğŸ’¾ ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹** - é«˜åº¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã‚¯ã‚¨ãƒªæœ€é©åŒ–ã‚’å‚™ãˆãŸ SQLite
- **ğŸ”„ ã‚¹ãƒãƒ¼ãƒˆãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³** - æˆåŠŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ã AI é§†å‹•ãƒ—ãƒ­ã‚­ã‚·é¸æŠ
- **ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰** - WebSocket æ›´æ–°ã¨ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ©ã‚¤ãƒ–ç›£è¦–
- **ğŸ› ï¸ API çµ±åˆ** - ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºè‡ªå‹•åŒ–ã¨çµ±åˆã®ãŸã‚ã® RESTful API

### ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

#### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ã¾ãŸã¯ venv\Scripts\activate  # Windows

# PyPIã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install proxy-meshx

# ã¾ãŸã¯æœ€æ–°æ©Ÿèƒ½ã®ãŸã‚ã«ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
git clone https://github.com/sheng1111/Proxy-Hunter.git
cd Proxy-Hunter
pip install -e .
```

**æ³¨æ„:** ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸åã¯ `proxy-meshx`ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã¯ `proxyhunter`ï¼š

```python
from proxyhunter import ProxyHunter, get_proxy
```

#### ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ä½¿ç”¨

```bash
# å¼·åŒ–æ¤œè¨¼ã«ã‚ˆã‚‹é«˜é€Ÿãƒ—ãƒ­ã‚­ã‚·ã‚¹ã‚­ãƒ£ãƒ³
proxyhunter scan --threads 30 --limit 100 --anonymous-only

# ãƒ¢ãƒ€ãƒ³Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®èµ·å‹•
proxyhunter web --port 8080

# ã¾ãŸã¯Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨
python -m proxyhunter.web_app
```

#### 1 è¡Œãƒ—ãƒ­ã‚­ã‚·ã‚¢ã‚¯ã‚»ã‚¹ ğŸ”¥

```python
from proxyhunter import get_proxy, get_proxies, get_socks_proxies, get_elite_proxies
import requests

# ä½œå‹•ã™ã‚‹ãƒ—ãƒ­ã‚­ã‚·ã‚’å³åº§ã«å–å¾—
proxy_url = get_proxy()
response = requests.get('https://httpbin.org/ip',
                       proxies={'http': proxy_url, 'https': proxy_url})
print(f"ã‚ãªãŸã®IP: {response.json()['origin']}")

# æœ€å°å“è³ªã‚¹ã‚³ã‚¢è¦ä»¶ã‚’æŒã¤é«˜å“è³ªUSãƒ—ãƒ­ã‚­ã‚·ã‚’å–å¾—
us_proxies = get_proxies(count=5, country='US', min_quality=70, max_response_time=2.0)
print(f"{len(us_proxies)}å€‹ã®é«˜å“è³ªUSãƒ—ãƒ­ã‚­ã‚·ã‚’ç™ºè¦‹")

# é«˜åº¦æ“ä½œç”¨SOCKSãƒ—ãƒ­ã‚­ã‚·ã‚’å–å¾—
socks_proxies = get_socks_proxies(count=3, protocol='socks5')
print(f"SOCKS5ãƒ—ãƒ­ã‚­ã‚·: {socks_proxies}")

# ãƒ¬ãƒƒãƒ‰ãƒãƒ¼ãƒ æ“ä½œç”¨EliteåŒ¿åãƒ—ãƒ­ã‚­ã‚·ã‚’å–å¾—
elite_proxies = get_elite_proxies(count=5)
print(f"Eliteãƒ—ãƒ­ã‚­ã‚·: {elite_proxies}")

# å“è³ªåˆ¶ç´„ã«ã‚ˆã‚‹åœ°ç†ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
uk_proxies = get_proxies(count=3, country='UK', min_quality=60, anonymous_only=True)
```

### ğŸŒ å¼·åŒ– Web ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ« Web ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹ã®èµ·å‹•ï¼š

```bash
python -m proxyhunter.web_app
# http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹
```

**æ–°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æ©Ÿèƒ½ï¼š**

- ğŸ“Š **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†æ** - WebSocket ã«ã‚ˆã‚‹ãƒ©ã‚¤ãƒ–ãƒ—ãƒ­ã‚­ã‚·çµ±è¨ˆ
- ğŸ“ˆ **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ£ãƒ¼ãƒˆ** - å¿œç­”æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰ã¨æˆåŠŸç‡åˆ†æ
- ğŸŒ **åœ°ç†çš„åˆ†å¸ƒ** - ãƒ—ãƒ­ã‚­ã‚·ä½ç½®ã‚’ç¤ºã™ä¸–ç•Œåœ°å›³
- ğŸ”„ **ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯æ“ä½œ** - å³åº§ã®ãƒ—ãƒ­ã‚­ã‚·æ›´æ–°ã¨æ¤œè¨¼
- ğŸ“‹ **ã‚¹ãƒãƒ¼ãƒˆã‚³ãƒ”ãƒ¼** - æ§˜ã€…ãªå½¢å¼ã§ã®ãƒ—ãƒ­ã‚­ã‚·ã‚³ãƒ”ãƒ¼ï¼ˆcurlã€requests ç­‰ï¼‰
- ğŸŒ **å¤šè¨€èª UI** - 3 è¨€èªã§ã®å®Œå…¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹
- ğŸ“± **ãƒ¢ãƒã‚¤ãƒ«å¯¾å¿œ** - å…¨ãƒ‡ãƒã‚¤ã‚¹ã§å®Œç’§å‹•ä½œ
- ğŸ¨ **ãƒ¢ãƒ€ãƒ³ãƒ‡ã‚¶ã‚¤ãƒ³** - ã‚¯ãƒªãƒ¼ãƒ³ã§ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ã‚¤ã‚¹

### ğŸš¦ ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

`/traffic`ã§ã®é«˜åº¦ç›£è¦–ã‚¢ã‚¯ã‚»ã‚¹ï¼š

```bash
# ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’èµ·å‹•ã— http://localhost:5000/traffic ã«ã‚¢ã‚¯ã‚»ã‚¹
python -m proxyhunter.web_app
```

**ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ç›£è¦–æ©Ÿèƒ½ï¼š**

- ğŸ“ˆ **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¿½è·¡** - å…¨ãƒ—ãƒ­ã‚­ã‚·ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ©ã‚¤ãƒ–ç›£è¦–
- ğŸ“Š **æˆåŠŸ/å¤±æ•—åˆ†æ** - è¦–è¦šçš„æˆåŠŸç‡åˆ†æ
- ğŸŒ **åœ°ç†çš„ä½¿ç”¨çµ±è¨ˆ** - å›½/åœ°åŸŸåˆ¥ãƒ—ãƒ­ã‚­ã‚·ä½¿ç”¨çŠ¶æ³
- â±ï¸ **å¿œç­”æ™‚é–“åˆ†æ** - è©³ç´°ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼çµ±è¨ˆ
- ğŸ“Š **ãƒ‡ãƒ¼ã‚¿è»¢é€ç›£è¦–** - ãƒ—ãƒ­ã‚­ã‚·ã”ã¨ã®å¸¯åŸŸå¹…ä½¿ç”¨é‡è¿½è·¡
- ğŸ”„ **ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†** - å…¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ã‚­ã‚·ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ç›£è¦–
- ğŸ“ **è©³ç´°ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°** - å®Œå…¨ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°
- ğŸš¦ **ãƒ©ã‚¤ãƒ–æ›´æ–°** - WebSocket é§†å‹•ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°

---

### ğŸ“‹ System Requirements

**Python**: 3.8+
**Memory**: 512MB minimum, 2GB+ recommended for heavy workloads
**Storage**: 100MB minimum
**Network**: Stable internet connection for proxy fetching

### ğŸ“ Enhanced Project Structure

```
Proxy-Hunter/
â”œâ”€â”€ proxyhunter/                    # Main package directory
â”‚   â”œâ”€â”€ __init__.py                # Enhanced quick access functions
â”‚   â”œâ”€â”€ __main__.py                # Command-line interface
â”‚   â”œâ”€â”€ core.py                    # Enhanced ProxyHunter with 15+ sources
â”‚   â”œâ”€â”€ proxy_session.py           # Smart ProxySession with rotation
â”‚   â”œâ”€â”€ web_app.py                 # Modern Flask dashboard
â”‚   â”œâ”€â”€ i18n.py                    # Internationalization support
â”‚   â”œâ”€â”€ i18n/                      # Translation files
â”‚   â”‚   â”œâ”€â”€ en.json                # English translations
â”‚   â”‚   â”œâ”€â”€ zh.json                # Traditional Chinese translations
â”‚   â”‚   â””â”€â”€ ja.json                # Japanese translations
â”‚   â””â”€â”€ public/                    # Enhanced web templates
â”‚       â”œâ”€â”€ index.html             # Main dashboard with analytics
â”‚       â””â”€â”€ traffic.html           # Traffic monitoring interface
â”œâ”€â”€ db/                            # Database directory (auto-created)
â”œâ”€â”€ tests/                         # Comprehensive test suite
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pyproject.toml                 # Python project configuration
â”œâ”€â”€ setup.py                      # Package installation script
â”œâ”€â”€ MANIFEST.in                    # Package manifest
â”œâ”€â”€ LICENSE                        # MIT License
â””â”€â”€ README.md                      # This enhanced documentation
```

### ğŸš€ Performance Benchmarks

- **Fetching Speed**: 15+ sources in parallel, ~500-2000 proxies in 10-30 seconds
- **Validation Speed**: 50 concurrent threads, ~100 proxies validated in 30-60 seconds
- **Success Rate**: Typically 10-30% working proxies depending on source quality
- **Memory Usage**: ~50-200MB depending on proxy count and concurrent operations
- **Database Performance**: SQLite with optimized indexes for sub-second queries

### ğŸ”§ Development & Contribution

```bash
git clone https://github.com/sheng1111/Proxy-Hunter.git
cd Proxy-Hunter
python -m venv venv
source venv/bin/activate  # Linux/Mac or venv\Scripts\activate on Windows
pip install -r requirements.txt
pip install -e .
```

### ğŸ“š API Documentation

Complete API documentation with examples:

- **English & ç¹é«”ä¸­æ–‡**: [API Documentation](wiki/API-Documentation.md)

<div align="center">

### ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### âš ï¸ Disclaimer

This tool is for educational and authorized security testing purposes only. Users are responsible for complying with applicable laws and regulations. The authors are not responsible for any misuse of this software.

**â­ Star this repository if you find it helpful!**

Made with â¤ï¸ for the security community

</div>
